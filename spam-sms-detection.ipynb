{"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":982,"sourceType":"datasetVersion","datasetId":483}],"dockerImageVersionId":30664,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n!pip install chardet\nimport chardet\nimport matplotlib.pyplot as plt","metadata":{"id":"0HL3K7v8hDnB","execution":{"iopub.status.busy":"2024-03-02T18:51:54.300051Z","iopub.execute_input":"2024-03-02T18:51:54.300602Z","iopub.status.idle":"2024-03-02T18:52:13.652977Z","shell.execute_reply.started":"2024-03-02T18:51:54.300536Z","shell.execute_reply":"2024-03-02T18:52:13.651403Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with open('/kaggle/input/sms-spam-collection-dataset/spam.csv', 'rb') as f:\n    encoding = chardet.detect(f.read())['encoding']","metadata":{"id":"vATwI7oHiaCB","outputId":"481f7d6c-7cda-4024-b91f-cf5a85fac673"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/sms-spam-collection-dataset/spam.csv', encoding=encoding)","metadata":{"id":"YtIht6rfhvwG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"id":"7YeJbA8sh3Mo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.isnull().sum()","metadata":{"id":"zgLcAiZKi11a"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Data Cleaning","metadata":{"id":"A_DFlSUOkP22"}},{"cell_type":"code","source":"df.drop(['Unnamed: 2','Unnamed: 3','Unnamed: 4'],axis=1,inplace=True)","metadata":{"id":"lcMAv4PyjT6S"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.rename({'v1':'target','v2':'text'},axis=1,inplace=True)","metadata":{"id":"3fyrJc2bkj4P"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['target']=df['target'].map({'ham':0,'spam':1})","metadata":{"id":"10BE-YuOpv9s"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#checking for duplicate values\ndf.duplicated().sum()","metadata":{"id":"-0BON77GqBqf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.drop_duplicates(keep='first',inplace=True)","metadata":{"id":"a3vZFYzhqw_g"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### EDA","metadata":{"id":"ScULyrudrFo8"}},{"cell_type":"code","source":"y=[df['target'].sum(),df.shape[0]-df['target'].sum()]\nplt.pie(y,labels=['spam','ham'],autopct='%1.2f%%')\nplt.show()","metadata":{"id":"l59mNdLPrHGh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import nltk","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"nltk.download('punkt')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['num_char']=df['text'].apply(len)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['num_word']=df['text'].apply(lambda x:len(nltk.word_tokenize(x)))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['num_sen']=df['text'].apply(lambda x:len(nltk.sent_tokenize(x)))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#for ham\ndf[df.target==0][['num_char','num_word','num_sen']].describe()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#for spam\ndf[df.target==1][['num_char','num_word','num_sen']].describe()\n#mean is more for spam messages","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import seaborn as sns","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(12,5))\nsns.histplot(df[df.target==0]['num_char'],label='ham')\nsns.histplot(df[df.target==1]['num_char'],color='red',label='spam')\nplt.legend()\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(12,5))\nsns.histplot(df[df.target==0]['num_word'],label='ham')\nsns.histplot(df[df.target==1]['num_word'],color='red',label='spam')\nplt.legend()\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.heatmap(df.select_dtypes(include='int').corr(),annot=True)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"since char has most correlation with target, we choose num_char for further use","metadata":{}},{"cell_type":"markdown","source":"### Text Processing\n-Lower Case <br>\n-Tokenization <br>\n-Removing Special Chars<br>\n-Removing stop words and punctuation<br>\n-Stemming<br>","metadata":{}},{"cell_type":"code","source":"from nltk.corpus import stopwords\nfrom nltk.stem.porter import PorterStemmer\nnltk.download('stopwords')\nimport string","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def transform_text(text):\n    text=text.lower()\n    text=nltk.word_tokenize(text)\n    \n    y=[]\n    for i in text:\n        if i.isalnum():\n            y.append(i)\n    \n    text.clear()        \n    for i in y:\n        if i not in stopwords.words('english') and i not in string.punctuation:\n            text.append(i)\n            \n    y.clear()\n    ps=PorterStemmer()\n    for i in text:\n        y.append(ps.stem(i))\n    \n    return \" \".join(y)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['transformed_text']=df['text'].apply(transform_text)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from wordcloud import WordCloud\nwc=WordCloud(width=500,height=500,min_font_size=10,background_color='white')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"spam_wc=wc.generate(df[df.target==1]['transformed_text'].str.cat(sep=' '))\nplt.figure(figsize=(12,6))\nplt.imshow(spam_wc)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ham_wc=wc.generate(df[df.target==0]['transformed_text'].str.cat(sep=' '))\nplt.figure(figsize=(12,6))\nplt.imshow(ham_wc)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#most ocurring words in spam\ny={}\nfor msg in df[df.target==1].transformed_text.tolist():\n    for word in msg.split():\n        y[word]=y.get(word,0)+1\n\nsorted_y=sorted(y.items(),key=lambda x:x[1],reverse=True)\ntop_words = [item[0] for item in sorted_y[:30]]\nword_counts = [item[1] for item in sorted_y[:30]]\nsns.barplot(x=top_words,y=word_counts)\nplt.xticks(rotation='vertical')\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#most ocurring words in spam\ny={}\nfor msg in df[df.target==0].transformed_text.tolist():\n    for word in msg.split():\n        y[word]=y.get(word,0)+1\n\nsorted_y=sorted(y.items(),key=lambda x:x[1],reverse=True)\ntop_words = [item[0] for item in sorted_y[:30]]\nword_counts = [item[1] for item in sorted_y[:30]]\nsns.barplot(x=top_words,y=word_counts)\nplt.xticks(rotation='vertical')\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Model Building","metadata":{}},{"cell_type":"code","source":"from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n#cv = CountVectorizer()  #bag of words\ntfidf = TfidfVectorizer(max_features=3000)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#X=cv.fit_transform(df['transformed_text']).toarray()   #returns a sparse matrix\ntfidf.fit(df['transformed_text'])\nX=tfidf.transform(df['transformed_text']).toarray()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y=df['target']","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=2)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.naive_bayes import GaussianNB,MultinomialNB,BernoulliNB\nfrom sklearn.metrics import accuracy_score,confusion_matrix,precision_score","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gnb=GaussianNB()\nmnb=MultinomialNB()\nbnb=BernoulliNB()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gnb.fit(X_train,y_train)\ny_pred1 = gnb.predict(X_test)\nprint(accuracy_score(y_test,y_pred1))\nprint(confusion_matrix(y_test,y_pred1))\nprint(precision_score(y_test,y_pred1))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mnb.fit(X_train,y_train)\ny_pred2 = mnb.predict(X_test)\nprint(accuracy_score(y_test,y_pred2))\nprint(confusion_matrix(y_test,y_pred2))\nprint(precision_score(y_test,y_pred2))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"bnb.fit(X_train,y_train)\ny_pred3 = bnb.predict(X_test)\nprint(accuracy_score(y_test,y_pred3))\nprint(confusion_matrix(y_test,y_pred3))\nprint(precision_score(y_test,y_pred3))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Since, precision maters the most here (false positive), we go with mnb","metadata":{}},{"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.ensemble import BaggingClassifier\nfrom sklearn.ensemble import ExtraTreesClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom xgboost import XGBClassifier","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"svc = SVC(kernel='sigmoid', gamma=1.0)\nknc = KNeighborsClassifier()\nmnb = MultinomialNB()\ndtc = DecisionTreeClassifier(max_depth=5)\nlrc = LogisticRegression(solver='liblinear', penalty='l1')\nrfc = RandomForestClassifier(n_estimators=50, random_state=2)\nabc = AdaBoostClassifier(n_estimators=50, random_state=2)\nbc = BaggingClassifier(n_estimators=50, random_state=2)\netc = ExtraTreesClassifier(n_estimators=50, random_state=2)\ngbdt = GradientBoostingClassifier(n_estimators=50,random_state=2)\nxgb = XGBClassifier(n_estimators=50,random_state=2)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"clfs = {\n    'SVC' : svc,\n    'KN' : knc, \n    'MNB': mnb, \n    'DT': dtc, \n    'LR': lrc, \n    'RF': rfc, \n    'AdaBoost': abc, \n    'BgC': bc, \n    'ETC': etc,\n    'GBDT':gbdt,\n    'xgb':xgb\n}","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train_classifier(clf,X_train,y_train,X_test,y_test):\n    clf.fit(X_train,y_train)\n    y_pred = clf.predict(X_test)\n    accuracy = accuracy_score(y_test,y_pred)\n    precision = precision_score(y_test,y_pred)\n    \n    return accuracy,precision","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"accuracy_scores = []\nprecision_scores = []\n\nfor name,clf in clfs.items():\n    \n    current_accuracy,current_precision = train_classifier(clf, X_train,y_train,X_test,y_test)\n    \n    print(\"For \",name)\n    print(\"Accuracy - \",current_accuracy)\n    print(\"Precision - \",current_precision)\n    \n    accuracy_scores.append(current_accuracy)\n    precision_scores.append(current_precision)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"performance_df = pd.DataFrame({'Algorithm':clfs.keys(),'Accuracy':accuracy_scores,'Precision':precision_scores}).sort_values(by='Precision',ascending=False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"performance_df","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"svc = SVC(kernel='sigmoid', gamma=1.0,probability=True)\nmnb = MultinomialNB()\netc = ExtraTreesClassifier(n_estimators=50, random_state=2)\n\nfrom sklearn.ensemble import VotingClassifier","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"A Voting Classifier is an ensemble learning method that combines the predictions of multiple base estimators (machine learning models) and predicts the class label by taking a vote.","metadata":{}},{"cell_type":"code","source":"voting = VotingClassifier(estimators=[('svm', svc), ('mnb', mnb), ('etc', etc)],voting='soft')\nvoting.fit(X_train,y_train)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred = voting.predict(X_test)\nprint(\"Accuracy\",accuracy_score(y_test,y_pred))\nprint(\"Precision\",precision_score(y_test,y_pred))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"A stacking classifier is an ensemble method where the output from multiple classifiers is passed as an input to a meta-classifier for the task of the final classification.","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import StackingClassifier","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"estimators=[('svm', svc), ('nb', mnb), ('et', etc)]\nfinal_estimator=RandomForestClassifier()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"clf = StackingClassifier(estimators=estimators, final_estimator=final_estimator)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"clf.fit(X_train,y_train)\ny_pred = clf.predict(X_test)\nprint(\"Accuracy\",accuracy_score(y_test,y_pred))\nprint(\"Precision\",precision_score(y_test,y_pred))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#best performance is observed in Multinomial-Naive Bayes\nmnb.fit(X_train,y_train)\ny_pred2 = mnb.predict(X_test)\nprint(accuracy_score(y_test,y_pred2))\nprint(confusion_matrix(y_test,y_pred2))\nprint(precision_score(y_test,y_pred2))","metadata":{},"execution_count":null,"outputs":[]}]}